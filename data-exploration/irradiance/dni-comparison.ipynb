{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Direct Normal Irradiance (DNI) Comparison\n",
    "\n",
    "This notebook compares actual DNI data from weather models with calculated DNI values using the `solarpy` library for the four equinox and solstice months (March, June, September, December)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "PVLib's Simplified Solis model most accurately fits the OpenMeteo DNI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dni_models import (\n",
    "    DniModel,\n",
    "    calculate_direct_normal_irradiance,\n",
    "    calculate_pvlib_dni_bulk,\n",
    "    load_dqydj_data,\n",
    "    get_cloud_cover_dni_coefficient\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Models to plot with their line styles\n",
    "# Note: Haurwitz model is not included as it only provides GHI, not DNI\n",
    "# Column names and display names will be automatically adjusted for cloud cover\n",
    "DNI_MODELS_TO_PLOT = [\n",
    "    (DniModel.SOLARPY, '--'),\n",
    "    (DniModel.PVLIB_INEICHEN, '-.'),\n",
    "    (DniModel.PVLIB_SIMPLIFIED_SOLIS, ':'),\n",
    "    # (DniModel.DQYDJ, (0, (3, 5))),  # Uncomment to include DQYDJ data\n",
    "]\n",
    "\n",
    "# Helper function to get adjusted column name and display name\n",
    "def get_adjusted_model_info(model):\n",
    "    \"\"\"Get the adjusted column name and display name for a model.\"\"\"\n",
    "    col_name = model.column_name + '_adjusted'\n",
    "    display_name = model.display_name + ' (adjusted)'\n",
    "    return col_name, display_name\n",
    "\n",
    "\n",
    "# Pre-identified sunniest days for each equinox/solstice month\n",
    "class Dates:\n",
    "    MARCH = '2023-03-02'\n",
    "    JUNE = '2023-06-08'\n",
    "    SEPTEMBER = '2023-09-05'\n",
    "    DECEMBER = '2022-12-15'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PV Site ID\n",
    "PV_SITE_ID = 24667\n",
    "\n",
    "# Weather model to analyze\n",
    "WEATHER_MODEL = 'ukmo_seamless'  # Options: best_match, dmi_seamless, gem_seamless, gfs_seamless, icon_seamless, jma_seamless, kma_seamless, knmi_seamless, meteofrance_seamless, metno_seamless, ukmo_seamless\n",
    "\n",
    "# Data directory - adjust path as needed\n",
    "DATA_DIR = Path('../data/data-1/timeseries')\n",
    "\n",
    "# Location parameters for DNI calculation\n",
    "# These should be set according to the site location\n",
    "# Example values - adjust based on actual site location\n",
    "LATITUDE = 51.8992\n",
    "LONGITUDE = -2.1288\n",
    "ALTITUDE = 0\n",
    "\n",
    "# Time offset for measured data alignment (in hours)\n",
    "# Positive value shifts measured data forward in time\n",
    "TIME_OFFSET_HOURS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files for the specified PV site\n",
    "csv_files = sorted(DATA_DIR.glob(f'{PV_SITE_ID}_*.csv'))\n",
    "print(f\"Found {len(csv_files)} CSV files for site {PV_SITE_ID}\")\n",
    "\n",
    "# Load and concatenate all data\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convert time to datetime\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Apply time offset to measured data for alignment\n",
    "data['time'] = data['time'] + pd.Timedelta(hours=TIME_OFFSET_HOURS)\n",
    "\n",
    "# Sort by time and remove duplicates\n",
    "data = data.sort_values('time').drop_duplicates(subset='time').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTotal records: {len(data)}\")\n",
    "print(f\"Date range: {data['time'].min()} to {data['time'].max()}\")\n",
    "print(f\"Applied time offset: {TIME_OFFSET_HOURS} hour(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Extract Date and Add Month Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date (without time)\n",
    "data['date'] = data['time'].dt.date\n",
    "\n",
    "# Add month information (aggregating across years)\n",
    "data['month'] = data['time'].dt.month\n",
    "data['month_name'] = data['time'].dt.strftime('%B')  # Full month name\n",
    "data['year'] = data['time'].dt.year\n",
    "\n",
    "# Filter for equinox and solstice months (March, June, September, December)\n",
    "equinox_solstice_months = [3, 6, 9, 12]\n",
    "data_filtered = data[data['month'].isin(equinox_solstice_months)].copy()\n",
    "\n",
    "# Create month labels\n",
    "month_names_map = {3: 'March', 6: 'June', 9: 'September', 12: 'December'}\n",
    "data_filtered['month_label'] = data_filtered['month'].map(month_names_map)\n",
    "\n",
    "print(f\"\\nFiltered to equinox/solstice months: {len(data_filtered)} records\")\n",
    "print(\"\\nMonths available in data:\")\n",
    "print(data_filtered.groupby('month_label')['date'].agg(['min', 'max', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Prepare Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for the selected weather model\n",
    "dni_col = f'direct_normal_irradiance_{WEATHER_MODEL}'\n",
    "cloud_cover_col = f'cloud_cover_{WEATHER_MODEL}'\n",
    "\n",
    "# Check if columns exist\n",
    "required_cols = [dni_col, cloud_cover_col]\n",
    "missing_cols = [col for col in required_cols if col not in data_filtered.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    print(f\"\\nAvailable columns containing '{WEATHER_MODEL}':\")\n",
    "    matching_cols = [col for col in data_filtered.columns if WEATHER_MODEL in col]\n",
    "    for col in matching_cols:\n",
    "        print(f\"  - {col}\")\n",
    "else:\n",
    "    print(f\"Found all required columns: {required_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Use Pre-identified Sunniest Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pre-identified dates to a DataFrame for easier processing\n",
    "from datetime import datetime\n",
    "\n",
    "sunniest_dates = {\n",
    "    'March': datetime.strptime(Dates.MARCH, '%Y-%m-%d').date(),\n",
    "    'June': datetime.strptime(Dates.JUNE, '%Y-%m-%d').date(),\n",
    "    'September': datetime.strptime(Dates.SEPTEMBER, '%Y-%m-%d').date(),\n",
    "    'December': datetime.strptime(Dates.DECEMBER, '%Y-%m-%d').date(),\n",
    "}\n",
    "\n",
    "print(f\"\\nUsing pre-identified sunniest days:\")\n",
    "for month_label, date in sunniest_dates.items():\n",
    "    print(f\"  {month_label}: {date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Load Third-Party DQYDJ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DQYDJ data files using the dni_models library\n",
    "dqydj_data = load_dqydj_data(dqydj_dir=Path('resources/dqydj'), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Plot DNI Comparison - Four Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DNI for all filtered data points\n",
    "print(\"Calculating DNI using solarpy...\")\n",
    "data_filtered['dni_calculated'] = data_filtered['time'].apply(\n",
    "    lambda dt: calculate_direct_normal_irradiance(dt, LATITUDE, LONGITUDE, ALTITUDE)\n",
    ")\n",
    "print(\"Solarpy DNI calculation complete!\")\n",
    "\n",
    "# Calculate DNI for all pvlib models\n",
    "# Note: Only Ineichen and Simplified Solis models provide DNI\n",
    "# Haurwitz only provides GHI and is therefore not included\n",
    "times_utc = pd.DatetimeIndex(data_filtered['time']).tz_localize('UTC')\n",
    "\n",
    "print(\"Calculating DNI using pvlib (Ineichen model)...\")\n",
    "data_filtered['dni_pvlib_ineichen'] = calculate_pvlib_dni_bulk(\n",
    "    times_utc, LATITUDE, LONGITUDE, ALTITUDE, model='ineichen'\n",
    ").values\n",
    "print(\"pvlib-Ineichen DNI calculation complete!\")\n",
    "\n",
    "\n",
    "print(\"Calculating DNI using pvlib (Simplified Solis model)...\")\n",
    "data_filtered['dni_pvlib_simplified_solis'] = calculate_pvlib_dni_bulk(\n",
    "    times_utc, LATITUDE, LONGITUDE, ALTITUDE, model='simplified_solis'\n",
    ").values\n",
    "print(\"pvlib-SimplifiedSolis DNI calculation complete!\")\n",
    "\n",
    "# Apply cloud cover adjustment to all calculated DNI models\n",
    "print(\"\\nApplying cloud cover adjustments to modelled DNI...\")\n",
    "cloud_cover = data_filtered[cloud_cover_col].values\n",
    "cloud_cover_coefficient = get_cloud_cover_dni_coefficient(cloud_cover)\n",
    "\n",
    "# Adjust each model's DNI by the cloud cover coefficient\n",
    "data_filtered['dni_calculated_adjusted'] = data_filtered['dni_calculated'] * cloud_cover_coefficient\n",
    "data_filtered['dni_pvlib_ineichen_adjusted'] = data_filtered['dni_pvlib_ineichen'] * cloud_cover_coefficient\n",
    "data_filtered['dni_pvlib_simplified_solis_adjusted'] = data_filtered['dni_pvlib_simplified_solis'] * cloud_cover_coefficient\n",
    "\n",
    "print(f\"Cloud cover adjustment complete!\")\n",
    "print(f\"  Cloud cover range: {cloud_cover.min():.2f} to {cloud_cover.max():.2f}\")\n",
    "print(f\"  Coefficient range: {cloud_cover_coefficient.min():.2f} to {cloud_cover_coefficient.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get months in chronological order\n",
    "months = ['March', 'June', 'September', 'December']\n",
    "\n",
    "# Define colors for seasonal context\n",
    "month_colors = {\n",
    "    'March': '#88CC88',      # Spring Equinox - light green\n",
    "    'June': '#FFD700',       # Summer Solstice - gold\n",
    "    'September': '#FF8C00',  # Autumn Equinox - orange\n",
    "    'December': '#4169E1'    # Winter Solstice - blue\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Weather Model Comparison - RMS Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMS error for each weather model and DNI model combination\n",
    "# Error is defined as: (modeled - measured) / peak_measured\n",
    "print(\"=\" * 80)\n",
    "print(\"WEATHER MODEL COMPARISON - RMS ERROR ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCalculating RMS errors for each weather model and DNI model combination...\")\n",
    "print(\"across the four dates of interest.\\n\")\n",
    "\n",
    "# Identify all available weather models from the data columns\n",
    "weather_models = []\n",
    "for col in data_filtered.columns:\n",
    "    if col.startswith('direct_normal_irradiance_') and not col.endswith('_adjusted'):\n",
    "        # Extract weather model name\n",
    "        weather_model_name = col.replace('direct_normal_irradiance_', '')\n",
    "        # Check if corresponding cloud_cover column exists\n",
    "        cloud_cover_column = f'cloud_cover_{weather_model_name}'\n",
    "        if cloud_cover_column in data_filtered.columns:\n",
    "            weather_models.append(weather_model_name)\n",
    "\n",
    "weather_models = sorted(set(weather_models))\n",
    "print(f\"Found {len(weather_models)} weather models with both DNI and cloud cover data:\")\n",
    "for wm in weather_models:\n",
    "    print(f\"  - {wm}\")\n",
    "print()\n",
    "\n",
    "# Get DNI models to analyze (excluding DQYDJ)\n",
    "dni_models_to_analyze = [(model, model_info) for model, model_info in\n",
    "                          [(m, get_adjusted_model_info(m)) for m, _ in DNI_MODELS_TO_PLOT]\n",
    "                          if model != DniModel.DQYDJ]\n",
    "\n",
    "# Dictionary to store RMS errors: {weather_model: {dni_model: rms_error}}\n",
    "rms_results = {}\n",
    "\n",
    "for weather_model in weather_models:\n",
    "    dni_col_wm = f'direct_normal_irradiance_{weather_model}'\n",
    "    cloud_cover_col_wm = f'cloud_cover_{weather_model}'\n",
    "\n",
    "    rms_results[weather_model] = {}\n",
    "\n",
    "    for dni_model, (col_name_suffix, display_name) in dni_models_to_analyze:\n",
    "        all_errors = []\n",
    "\n",
    "        for month_label in months:\n",
    "            date = sunniest_dates[month_label]\n",
    "\n",
    "            # Get hourly data for this day\n",
    "            day_data = data_filtered[data_filtered['date'] == date].copy()\n",
    "\n",
    "            if len(day_data) == 0:\n",
    "                continue\n",
    "\n",
    "            # Get measured DNI from this weather model\n",
    "            if dni_col_wm not in day_data.columns:\n",
    "                continue\n",
    "\n",
    "            measured_dni = day_data[dni_col_wm].values\n",
    "            peak_measurement = np.max(measured_dni)\n",
    "\n",
    "            if peak_measurement <= 0:\n",
    "                continue\n",
    "\n",
    "            # Get the modeled DNI (adjusted by cloud cover from this weather model)\n",
    "            # We need to use the base DNI model column\n",
    "            base_col_name = dni_model.column_name\n",
    "            if base_col_name not in day_data.columns:\n",
    "                continue\n",
    "\n",
    "            # Apply cloud cover adjustment specific to this weather model\n",
    "            cloud_cover_wm = day_data[cloud_cover_col_wm].values\n",
    "            cloud_cover_coefficient_wm = get_cloud_cover_dni_coefficient(cloud_cover_wm)\n",
    "            modeled_dni_adjusted = day_data[base_col_name].values * cloud_cover_coefficient_wm\n",
    "\n",
    "            # Calculate normalized errors for this day\n",
    "            errors = (modeled_dni_adjusted - measured_dni) / peak_measurement * 100\n",
    "            all_errors.extend(errors)\n",
    "\n",
    "        if all_errors:\n",
    "            # Calculate RMS error\n",
    "            rms_error = np.sqrt(np.mean(np.array(all_errors)**2))\n",
    "            rms_results[weather_model][dni_model] = rms_error\n",
    "        else:\n",
    "            rms_results[weather_model][dni_model] = np.nan\n",
    "\n",
    "# Create a formatted table\n",
    "print(\"RMS Error (%) - Weather Models vs DNI Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get DNI model names for header\n",
    "dni_model_names = [display_name for _, (_, display_name) in dni_models_to_analyze]\n",
    "dni_models_list = [dni_model for dni_model, _ in dni_models_to_analyze]\n",
    "\n",
    "# Print header\n",
    "header = f\"{'Weather Model':<30}\"\n",
    "for name in dni_model_names:\n",
    "    header += f\"{name:>20}\"\n",
    "print(header)\n",
    "print(\"-\" * (30 + 20 * len(dni_model_names)))\n",
    "\n",
    "# Print data rows\n",
    "for weather_model in weather_models:\n",
    "    row = f\"{weather_model:<30}\"\n",
    "    for dni_model in dni_models_list:\n",
    "        rms = rms_results[weather_model].get(dni_model, np.nan)\n",
    "        if np.isnan(rms):\n",
    "            row += f\"{'N/A':>20}\"\n",
    "        else:\n",
    "            row += f\"{rms:>20.2f}\"\n",
    "    print(row)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best weather model for each DNI model\n",
    "print(\"\\nBest Weather Model for Each DNI Model:\")\n",
    "print(\"-\" * 80)\n",
    "for idx, dni_model in enumerate(dni_models_list):\n",
    "    dni_name = dni_model_names[idx]\n",
    "    best_weather_model = None\n",
    "    best_rms = float('inf')\n",
    "\n",
    "    for weather_model in weather_models:\n",
    "        rms = rms_results[weather_model].get(dni_model, np.nan)\n",
    "        if not np.isnan(rms) and rms < best_rms:\n",
    "            best_rms = rms\n",
    "            best_weather_model = weather_model\n",
    "\n",
    "    if best_weather_model:\n",
    "        print(f\"  {dni_name:<40} -> {best_weather_model:<25} (RMS: {best_rms:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  {dni_name:<40} -> No valid data\")\n",
    "\n",
    "# Find best DNI model for each weather model\n",
    "print(\"\\nBest DNI Model for Each Weather Model:\")\n",
    "print(\"-\" * 80)\n",
    "for weather_model in weather_models:\n",
    "    best_dni_model = None\n",
    "    best_rms = float('inf')\n",
    "\n",
    "    for idx, dni_model in enumerate(dni_models_list):\n",
    "        rms = rms_results[weather_model].get(dni_model, np.nan)\n",
    "        if not np.isnan(rms) and rms < best_rms:\n",
    "            best_rms = rms\n",
    "            best_dni_model = dni_model_names[idx]\n",
    "\n",
    "    if best_dni_model:\n",
    "        print(f\"  {weather_model:<30} -> {best_dni_model:<40} (RMS: {best_rms:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  {weather_model:<30} -> No valid data\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Plot DNI Comparison - Separate Subplots by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily disable interactive plotting to prevent the inline backend\n",
    "# from auto-rendering figures (which can cause double outputs). We'll\n",
    "# restore the previous interactive state after displaying/closing the figures.\n",
    "_prev_interactive_state = plt.isinteractive()\n",
    "plt.ioff()\n",
    "\n",
    "# Create first figure with DNI plots (2x2)\n",
    "fig_dni, axes_dni = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig_dni.suptitle(f'Direct Normal Irradiance: Measured vs Calculated by Month',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "dni_axes = axes_dni.flatten()\n",
    "\n",
    "# Create second figure with error plots (2x2)\n",
    "fig_error, axes_error = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig_error.suptitle(f'Model Errors: (Calculated - Measured) / Peak Measurement',\n",
    "                   fontsize=16, fontweight='bold')\n",
    "error_axes = axes_error.flatten()\n",
    "\n",
    "# Plot each month's sunniest day in its own subplot\n",
    "for idx, month_label in enumerate(months):\n",
    "    date = sunniest_dates[month_label]\n",
    "\n",
    "    # Get hourly data for this day\n",
    "    day_data = data_filtered[data_filtered['date'] == date].copy()\n",
    "    day_data = day_data.sort_values('time')\n",
    "\n",
    "    # Extract hour for x-axis\n",
    "    hours = day_data['time'].dt.hour + day_data['time'].dt.minute / 60\n",
    "\n",
    "    color = month_colors.get(month_label, 'blue')\n",
    "\n",
    "    # Get measured DNI values\n",
    "    measured_dni = day_data[dni_col].values\n",
    "\n",
    "    # Plot measured DNI as circle markers only (no line)\n",
    "    dni_axes[idx].plot(hours, measured_dni, linestyle='', marker='o',\n",
    "                      label='Measured', markersize=6, color=color, alpha=0.8)\n",
    "\n",
    "    # Plot models based on DNI_MODELS_TO_PLOT configuration\n",
    "    for model, linestyle in DNI_MODELS_TO_PLOT:\n",
    "        col_name, display_name = get_adjusted_model_info(model)\n",
    "        if model == DniModel.DQYDJ:\n",
    "            # Special handling for DQYDJ data (different source)\n",
    "            if month_label in dqydj_data:\n",
    "                dqydj_day = dqydj_data[month_label]\n",
    "                dqydj_hours = dqydj_day['time'].dt.hour + dqydj_day['time'].dt.minute / 60\n",
    "                dni_axes[idx].plot(dqydj_hours, dqydj_day['dni_wm2'], linestyle=linestyle,\n",
    "                                  label=display_name, linewidth=2.5, color=color, alpha=0.9)\n",
    "        else:\n",
    "            # Plot calculated DNI from data columns\n",
    "            if col_name in day_data.columns:\n",
    "                dni_axes[idx].plot(hours, day_data[col_name], linestyle=linestyle,\n",
    "                                  label=display_name, linewidth=2.5, color=color, alpha=0.9)\n",
    "\n",
    "    # Configure DNI subplot\n",
    "    dni_axes[idx].set_title(f'{month_label} - {date}', fontsize=12, fontweight='bold')\n",
    "    dni_axes[idx].set_xlabel('Hour of Day', fontsize=10)\n",
    "    dni_axes[idx].set_ylabel('DNI (W/mÂ²)', fontsize=10)\n",
    "    dni_axes[idx].legend(loc='best', fontsize=9)\n",
    "    dni_axes[idx].grid(True, alpha=0.3)\n",
    "    dni_axes[idx].set_xlim(0, 24)\n",
    "    dni_axes[idx].set_ylim(bottom=0)\n",
    "\n",
    "    # Calculate percentage errors: (calculated - measured) / peak_measurement * 100\n",
    "    # where peak_measurement is the peak measured DNI for this day\n",
    "    peak_measurement = np.max(measured_dni)\n",
    "\n",
    "    if peak_measurement > 0:\n",
    "        # Plot errors for each model in DNI_MODELS_TO_PLOT\n",
    "        for model, linestyle in DNI_MODELS_TO_PLOT:\n",
    "            col_name, display_name = get_adjusted_model_info(model)\n",
    "            if model == DniModel.DQYDJ:\n",
    "                # Special handling for DQYDJ data (different source)\n",
    "                if month_label in dqydj_data:\n",
    "                    dqydj_day = dqydj_data[month_label]\n",
    "                    dqydj_hours = dqydj_day['time'].dt.hour + dqydj_day['time'].dt.minute / 60\n",
    "\n",
    "                    # Match DQYDJ times to measured data times\n",
    "                    dqydj_dni = dqydj_day['dni_wm2'].values\n",
    "                    dqydj_error_list = []\n",
    "                    dqydj_hours_matched = []\n",
    "\n",
    "                    for h, m_dni in zip(hours, measured_dni):\n",
    "                        # Find closest DQYDJ hour\n",
    "                        idx_closest = np.argmin(np.abs(dqydj_hours - h))\n",
    "                        if np.abs(dqydj_hours.iloc[idx_closest] - h) < 0.5:  # Within 30 minutes\n",
    "                            dqydj_error = ((dqydj_dni[idx_closest] - m_dni) / peak_measurement) * 100\n",
    "                            dqydj_error_list.append(dqydj_error)\n",
    "                            dqydj_hours_matched.append(h)\n",
    "\n",
    "                    if dqydj_error_list:\n",
    "                        error_axes[idx].plot(dqydj_hours_matched, dqydj_error_list, linestyle=linestyle,\n",
    "                                            label=display_name, linewidth=2.5, color=color, alpha=0.9)\n",
    "            else:\n",
    "                # Calculate error from data columns\n",
    "                if col_name in day_data.columns:\n",
    "                    model_error = ((day_data[col_name].values - measured_dni) / peak_measurement) * 100\n",
    "                    error_axes[idx].plot(hours, model_error, linestyle=linestyle,\n",
    "                                        label=display_name, linewidth=2.5, color=color, alpha=0.9)\n",
    "\n",
    "        # Add zero reference line\n",
    "        error_axes[idx].axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.3)\n",
    "\n",
    "        # Configure error subplot\n",
    "        error_axes[idx].set_title(f'{month_label} - Error', fontsize=12, fontweight='bold')\n",
    "        error_axes[idx].set_xlabel('Hour of Day', fontsize=10)\n",
    "        error_axes[idx].set_ylabel('Error (%)', fontsize=10)\n",
    "        error_axes[idx].legend(loc='best', fontsize=9)\n",
    "        error_axes[idx].grid(True, alpha=0.3)\n",
    "        error_axes[idx].set_xlim(0, 24)\n",
    "\n",
    "# Show both figures\n",
    "from IPython.display import display\n",
    "\n",
    "# Ensure nice layout then explicitly display the DNI figure first, followed by the error figure\n",
    "fig_dni.tight_layout()\n",
    "display(fig_dni)\n",
    "plt.close(fig_dni)\n",
    "\n",
    "fig_error.tight_layout()\n",
    "display(fig_error)\n",
    "plt.close(fig_error)\n",
    "\n",
    "# Restore interactive plotting state\n",
    "if _prev_interactive_state:\n",
    "    plt.ion()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
