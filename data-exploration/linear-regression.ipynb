{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "## Data Loading\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import deg2rad\n",
    "from pandas import DataFrame\n",
    "from pytz import timezone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from solarpy import standard2solar_time, irradiance_on_plane, beam_irradiance\n",
    "from spherical_coordinates import az_zd_to_cx_cy_cz\n",
    "\n",
    "# Root directory for datasets\n",
    "DATASETS_ROOT = '../data/data-1'\n",
    "\n",
    "SYSTEM_ID = '4708'\n",
    "AZIMUTHS = [90, 270]\n",
    "ELEVATIONS = [30, 30]\n",
    "AREA_FRACTIONS = [0.5, 0.5]\n",
    "LATITUDE = 51.8144\n",
    "LONGITUDE = -0.2949\n",
    "ALTITUDE = 0\n",
    "\n",
    "UKTZ = timezone('Europe/London')\n",
    "UTC = timezone('UTC')\n",
    "\n",
    "# Set dark mode style for all plots\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# OPENMETEO_FORECAST_MODEL = 'best_match'\n",
    "# OPENMETEO_FORECAST_MODEL = 'metno_seamless'\n",
    "# OPENMETEO_FORECAST_MODEL = 'icon_seamless'\n",
    "OPENMETEO_FORECAST_MODEL = 'ukmo_seamless'\n",
    "OPENMETEO_FIELDS = [\n",
    "    'direct_normal_irradiance',\n",
    "    'diffuse_radiation',\n",
    "    'temperature_2m',\n",
    "    'cloud_cover',\n",
    "]\n",
    "\n",
    "PVOUTPUT_FIELDS = ['energy', 'average']\n",
    "\n",
    "\n",
    "def load_data(\n",
    "        file_path: str, datetime_extractor: Callable[[DataFrame], datetime], fields: list[str],\n",
    "        suffix: str | None = None, renamer: dict[str, str] = None,\n",
    ") -> pd.DataFrame:\n",
    "    df = pd.read_csv(Path(DATASETS_ROOT, file_path))\n",
    "    df['datetime'] = datetime_extractor(df)\n",
    "    if suffix:\n",
    "        suffixed_fields = [\n",
    "            f\"{field}_{suffix}\" for field in fields\n",
    "        ]\n",
    "        df.rename(columns=dict(zip(suffixed_fields, fields)), inplace=True)\n",
    "\n",
    "    df = df[['datetime', *fields]]\n",
    "\n",
    "    if renamer:\n",
    "        df.rename(columns=renamer, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "weather_qhourly = load_data(\n",
    "    f'openmeteo-quarterhourly_{SYSTEM_ID}.csv',\n",
    "    lambda df: pd.to_datetime(df['time']),\n",
    "    OPENMETEO_FIELDS,\n",
    "    suffix=OPENMETEO_FORECAST_MODEL,\n",
    ")\n",
    "\n",
    "weather_hourly = load_data(\n",
    "    f'openmeteo-historical_{SYSTEM_ID}.csv',\n",
    "    lambda df: pd.to_datetime(df['time']),\n",
    "    OPENMETEO_FIELDS,\n",
    "    suffix=OPENMETEO_FORECAST_MODEL,\n",
    ")\n",
    "\n",
    "weather = pd.concat([weather_hourly, weather_qhourly]).drop_duplicates('datetime').sort_values('datetime').reset_index(\n",
    "    drop=True)\n",
    "\n",
    "pv = load_data(\n",
    "    f'pvoutput_{SYSTEM_ID}.csv',\n",
    "    lambda df: pd.to_datetime(df['date'].astype(str) + 'T' + df['time']),\n",
    "    PVOUTPUT_FIELDS,\n",
    "    renamer={'average': 'power'},\n",
    ")\n",
    "\n",
    "\n",
    "def verify_average_powers() -> None:\n",
    "    power_computed = pv['energy'].diff() * 3600 / pv['datetime'].diff().dt.total_seconds()\n",
    "    mask = power_computed.notna() & pv['power'].notna()\n",
    "    max_error = max(power_computed[mask] - pv['power'][mask])\n",
    "    assert max_error == 0, f'Max error: {max_error}'\n",
    "\n",
    "\n",
    "verify_average_powers()\n",
    "\n",
    "weather['blue_sky_index'] = 1 - weather['cloud_cover'] / 100\n",
    "weather.drop('cloud_cover', axis=1, inplace=True)\n",
    "\n",
    "joined = pv.join(weather.set_index('datetime'), on='datetime', how='inner')\n",
    "joined.dropna(inplace=True)\n",
    "\n",
    "\n",
    "def calc_v_norm(az, el):\n",
    "    cx_cy_cz = az_zd_to_cx_cy_cz(deg2rad(az), deg2rad(el))\n",
    "    return cx_cy_cz[0], cx_cy_cz[1], -cx_cy_cz[2]\n",
    "\n",
    "\n",
    "v_norms = [\n",
    "    calc_v_norm(az, el) for az, el in zip(AZIMUTHS, ELEVATIONS)\n",
    "]\n",
    "\n",
    "\n",
    "def to_utc(dt_local):\n",
    "    return UKTZ.localize(dt_local).astimezone(UTC)\n",
    "\n",
    "\n",
    "# Lookup table: blue_sky_index -> irradiance_factor\n",
    "BLUE_SKY_INDEX_TABLE = np.array([0.0, 0.5, 1.0])\n",
    "IRRADIANCE_FACTOR_TABLE = np.array([0.2, 0.7, 1.0])\n",
    "\n",
    "\n",
    "def modified_by_blue_sky_index(func):\n",
    "    \"\"\"Decorator that modifies irradiance calculation based on blue sky index.\"\"\"\n",
    "\n",
    "    def wrapper(dt: datetime, blue_sky_index: float) -> float:\n",
    "        irradiance = func(dt)\n",
    "        # Linear interpolation between table values\n",
    "        irradiance_factor = np.interp(blue_sky_index, BLUE_SKY_INDEX_TABLE, IRRADIANCE_FACTOR_TABLE)\n",
    "        return irradiance * irradiance_factor\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@modified_by_blue_sky_index\n",
    "def calculate_irradiance_on_panels(dt: datetime) -> float:\n",
    "    solar_time = standard2solar_time(to_utc(dt), LONGITUDE)\n",
    "\n",
    "    irradiances_per_panel_group = [\n",
    "        max(0., irradiance_on_plane(v_norm, ALTITUDE, solar_time, LATITUDE)) * area_frac\n",
    "        for v_norm, area_frac in zip(v_norms, AREA_FRACTIONS)\n",
    "    ]\n",
    "    return sum(irradiances_per_panel_group)\n",
    "\n",
    "\n",
    "@modified_by_blue_sky_index\n",
    "def calculate_direct_normal_irradiance(dt: datetime) -> float:\n",
    "    solar_time = standard2solar_time(to_utc(dt), LONGITUDE)\n",
    "    return max(0., beam_irradiance(ALTITUDE, solar_time, LATITUDE))\n",
    "\n",
    "\n",
    "joined['calculated_irradiance_on_panels'] = joined.apply(\n",
    "    lambda row: calculate_irradiance_on_panels(row['datetime'], row['blue_sky_index']), axis=1\n",
    ")\n",
    "\n",
    "joined['calculated_direct_normal_irradiance'] = joined.apply(\n",
    "    lambda row: calculate_direct_normal_irradiance(row['datetime'], row['blue_sky_index']), axis=1\n",
    ")\n",
    "\n",
    "X, y = train_test_split(joined, test_size=0.2, random_state=42)\n",
    "X.sort_index(inplace=True)\n",
    "\n",
    "# X = X[X['blue_sky_index'] == 1.0]\n",
    "# X = X[X['datetime'] >= pd.to_datetime('2025-06-01')]\n",
    "\n",
    "# X.head(n=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, AutoDateLocator\n",
    "\n",
    "days_of_interest = [\n",
    "    # '2025-03-18',\n",
    "    # '2025-05-10',\n",
    "    # '2025-04-07',\n",
    "    # '2025-08-25',\n",
    "\n",
    "    '2025-03-18',\n",
    "    # '2025-03-29',\n",
    "    '2025-03-30',\n",
    "    # '2025-03-31',\n",
    "]\n",
    "\n",
    "# Create 2-by-N grid\n",
    "n_days = len(days_of_interest)\n",
    "fig, axes = plt.subplots(2, n_days, figsize=(6 * n_days, 7), sharex='col', sharey='row')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col, date_str in enumerate(days_of_interest):\n",
    "    # Filter data for this day\n",
    "    start = pd.to_datetime(date_str)\n",
    "    end = start + pd.Timedelta(days=1)\n",
    "    mask = (joined['datetime'] >= start) & (joined['datetime'] < end)\n",
    "    sub = joined.loc[mask].sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "    # Top row: irradiance plots\n",
    "    ax_top = axes[0, col]\n",
    "    ax_top.plot(sub['datetime'], sub['direct_normal_irradiance'],\n",
    "                label='direct_normal', color='tab:orange', marker='o', linestyle='-', markersize=4)\n",
    "    ax_top.plot(sub['datetime'], sub['calculated_direct_normal_irradiance'],\n",
    "                label='calculated direct normal', color='tab:cyan', alpha=0.9, marker='o', linestyle='-', markersize=4)\n",
    "    ax_top.plot(sub['datetime'], sub['calculated_irradiance_on_panels'],\n",
    "                label='calculated on panels', color='tab:green', alpha=0.9, marker='o', linestyle='-', markersize=4)\n",
    "    ax_top.set_title(date_str, fontsize=12, fontweight='bold')\n",
    "    ax_top.grid(alpha=0.25)\n",
    "\n",
    "    # Only show y-label on leftmost plot\n",
    "    if col == 0:\n",
    "        ax_top.set_ylabel('Irradiance (W/mÂ²)')\n",
    "        ax_top.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "    # Bottom row: blue sky index\n",
    "    ax_bottom = axes[1, col]\n",
    "    ax_bottom.plot(sub['datetime'], sub['blue_sky_index'],\n",
    "                   marker='o', label='blue_sky_index', color='tab:blue', markersize=4)\n",
    "    ax_bottom.set_xlabel('Time')\n",
    "    ax_bottom.grid(alpha=0.25)\n",
    "    ax_bottom.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    # Only show y-label on leftmost plot\n",
    "    if col == 0:\n",
    "        ax_bottom.set_ylabel('Blue sky index')\n",
    "\n",
    "    # Format x-axis\n",
    "    date_fmt = DateFormatter('%H:%M')\n",
    "    ax_bottom.xaxis.set_major_formatter(date_fmt)\n",
    "    ax_bottom.xaxis.set_major_locator(AutoDateLocator())\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    for tick in ax_bottom.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "        tick.set_ha('right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "temp = X[X['datetime'] >= pd.to_datetime('2025-03-30T00:00')]\n",
    "temp = temp[temp['datetime'] <= pd.to_datetime('2025-03-31T00:00')]\n",
    "\n",
    "temp.head(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Finding Days with Most Contiguous Blue Sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify days with the most contiguous blue sky (index == 1.0)\n",
    "import pandas as pd\n",
    "\n",
    "# Add date column for grouping\n",
    "joined['date'] = joined['datetime'].dt.date\n",
    "\n",
    "# Filter for blue sky conditions\n",
    "blue_sky = joined[joined['blue_sky_index'] == 1.0].copy()\n",
    "blue_sky = blue_sky.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# Find contiguous sequences\n",
    "blue_sky['time_diff'] = blue_sky['datetime'].diff()\n",
    "blue_sky['new_sequence'] = (blue_sky['time_diff'] > pd.Timedelta(hours=1)) | blue_sky['time_diff'].isna()\n",
    "blue_sky['sequence_id'] = blue_sky['new_sequence'].cumsum()\n",
    "\n",
    "# Calculate sequence lengths (in hours)\n",
    "sequence_stats = blue_sky.groupby('sequence_id').agg({\n",
    "    'datetime': ['min', 'max', 'count'],\n",
    "    'date': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "sequence_stats.columns = ['sequence_id', 'start_time', 'end_time', 'count', 'date']\n",
    "sequence_stats['duration_hours'] = (sequence_stats['end_time'] - sequence_stats['start_time']).dt.total_seconds() / 3600\n",
    "\n",
    "# Sort by duration\n",
    "sequence_stats_sorted = sequence_stats.sort_values('duration_hours', ascending=False)\n",
    "\n",
    "print(\"Top 20 Contiguous Blue Sky Periods:\")\n",
    "print(\"=\" * 100)\n",
    "for idx, row in sequence_stats_sorted.head(20).iterrows():\n",
    "    print(f\"Date: {row['date']}, Duration: {row['duration_hours']:.2f} hours, \"\n",
    "          f\"Count: {row['count']}, Start: {row['start_time']}, End: {row['end_time']}\")\n",
    "\n",
    "# Also find days with most total blue sky hours\n",
    "daily_blue_sky = blue_sky.groupby('date').agg({\n",
    "    'datetime': 'count'\n",
    "}).reset_index()\n",
    "daily_blue_sky.columns = ['date', 'blue_sky_count']\n",
    "daily_blue_sky = daily_blue_sky.sort_values('blue_sky_count', ascending=False)\n",
    "\n",
    "print(\"\\n\\nTop 20 Days with Most Total Blue Sky Hours:\")\n",
    "print(\"=\" * 100)\n",
    "for idx, row in daily_blue_sky.head(20).iterrows():\n",
    "    # Calculate approximate hours (depends on data frequency)\n",
    "    print(f\"Date: {row['date']}, Blue Sky Records: {row['blue_sky_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, AutoDateLocator\n",
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
